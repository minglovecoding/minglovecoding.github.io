---
title: LLM中的一些基本概念
date: 2024-01-12 16:13:52
---

> 逐步系统化地了解一下

<!--more-->

# ☝ 基本概念

## 1、预训练（Pre-training）

预训练是指在特定任务前，让模型在大规模数据上进行训练的过程。预训练可以使模型学习到数据中的通用特征，从而在后续任务中取得更好的性能
## 2、微调（Fine-Tuning）

微调是在预训练模型的基础上，使用标注数据对模型进行进一步训练，以适应特征任务的方法。微调可以使预训练模型在目标任务上具有更好的效果。

## 3、强化学习（Reinforcement Learning,RL）

强化学习事一种人工智能技术，通过让智能体在环境中尝试行动，根据行动的结果来调整策略，以实现某种目标的方法。强化学习算法主要关注如何通过试错学习来优化决策过程。

## 4、人类反馈强化学习（Reinforcement Learning from Human Feedback，RLHF）

RLHF是一种基于人类反馈的强化学习方法，通过学习人类提供的奖励信号和反馈来训练智能体，其宗旨是使智能体能更好地是适应人类的需求和偏好

## 5、思维链（Chain of Thoughts，CoT）

思维链是一种表达人类推理过程的方法。通过一系列的逻辑推理步骤将从初始条件和结论相连。（就像数学公式的推理）。在人工智能领域，思维链可以用于表达模型在解决问题时的推理过程。

## 6、涌现（Emergence）

涌现是指在一个复杂系统中，通过相互作用和反馈机制产生的宏观现象。大模型能力的涌现是指：当模型达到一定规模（如计算量、模型参数或者数据集大小）时，模型会表现出意想不到的能力，这些能力在小规模模型中是不存在的。

## 7、泛化（Generalization）

泛化是指模型在训练集数据集上学到的知识能否在测试数据集上取得较好性能的能力。一个好的模型应该具备较好的泛化能力，从而在新数据上取得更好的表现。

## 8、幻觉（hallucination）

大模型的幻觉是指模型在生成的内容产生了一些和现实世界/用户输入不一致的现象。大模型的幻觉可以分为事实性幻觉（Factuality Hullucination）和忠实性幻觉（Faithfulness Huallunination）。

## 9、Transformer

Transformer是一种神经网络结构，之前一直用于自然语言处理任务。它采用的是自注意力机制（Self-Attention Mechanism）来捕捉输入序列中的长距离依赖关系。

## 10、注意力机制（Attention Mechanism）

注意力机制是一种计算方法，用户在输入序列中动态的分配权重。在Transformer结构中，注意力机制可以帮助模型在处理场序列时只关注与当前目标相关的部分，从而提好计算效率和性能。

## 11、自回归（Autoregressive）

自回归是一种生成模型，通过逐个预测序列中的元素，从而从前往后地生成序列。

## 12、Token

在自然语言处理中，Token是指文本的最小单元，可以是单词、字符或者其他语言单位。在深度学习中，Token用于表示输入数据的基本元素，以便进行编码和处理。

## 13、指令微调（instruction Tuning，IT）

指令微调是针对指令生成任务的语言模型预训练方法，通过让模型学习指令和形影的输入之间的关系，提高指令生成任务的性能。

## 14、温度（Temperature）

在生成模型中，温度参数用于控制生成过程的随机性。较低的温度会导致生成的结果更加具有确定性，相反会使得生成结果更加随机。

## 15、Top-p

Top-p是一种用于生成模型中的概率分布策略。它通过保留输入序列中概率前p的元素，来控制生成过程中的词汇多样性。

## 16、自监督

自监督学习是一种无监督学习方法，即模型可以在没有标签的数据上学习到有用的特征表示。在大模型中，自监督可以作为一种在无标签数据上进行预训练的方法。

## 17、检索增强生成（RAG，Retrieval Augmented Generation）

RAG是是通过检索获取知识库里面的相关知识，并将其融入到Prompt中，让大模型能够参考相应的知识从而给出合理的答案。其核心是“检索+生成”。

## 18、混合专家模型（MOE，Mixture of Experts）

MOE是一种稀疏门控制的深度学习模型，它主要由一组专家模型（Experts）和一个门控模型（GateNe）组成。MoE的基本理念是将输入数据根据任务类型分割成多个区域，并将每个区域的数据分配一个或多个专家模型。每个专家模型可以专注于处理输入这部分数据，从而提高模型的整体性能。简单理解就是：术业有专攻+三个臭皮匠，顶个诸葛亮。代表作品Mistral 8x7B。

## 19、多模态大模型（Multimodal Large Language Models, MLLM）

文本、语音、图像等等，这些都可以称为是一种模态。多模态就是对Language、Vision、Audio进行联合建模。包括到3d, radar, point cloud, structure (e.g. layout, markup language)。**多模态大模型**就是一个端到端的具备多种模态输入，多种模态输出的大模型。



